{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gzip\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate PCA-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_gen(root_path='./raw_data/mnist', img_saving_path='./avmnist/image', labels_saving_path='./avmnist/'):\n",
    "    file_names = {'train_data': 'train-images-idx3-ubyte.gz', 'train_labels': 'train-labels-idx1-ubyte.gz',\n",
    "                  'test_data': 't10k-images-idx3-ubyte.gz', 'test_labels': 't10k-labels-idx1-ubyte.gz'}\n",
    "\n",
    "    working_dir = os.getcwd()\n",
    "    print(\"Script working directory: %s\" % working_dir)\n",
    "\n",
    "    for key, file_name in file_names.items():\n",
    "        file_path = os.path.join(root_path, file_name)\n",
    "        print('file: %s' % key)\n",
    "        with gzip.open(file_path, 'rb') as f:\n",
    "            # read the definition of idx1-ubyte and idx3-ubyte\n",
    "            f.seek(4)\n",
    "            num = f.read(4)\n",
    "            num = int().from_bytes(num, 'big')\n",
    "            print('size of %s : %d' % (key, num))\n",
    "            if re.match(r'.*data.*', key) is not None:\n",
    "                height = f.read(4)\n",
    "                height = int().from_bytes(height, 'big')\n",
    "                width = f.read(4)\n",
    "                width = int().from_bytes(width, 'big')\n",
    "\n",
    "                data = np.frombuffer(f.read(), np.uint8).reshape(num, height, width)\n",
    "\n",
    "                # PCA projecting with 75% energy removing\n",
    "                # n_comp = int(height * width)\n",
    "                # pca = PCA(n_components=n_comp)\n",
    "                # projected = pca.fit_transform(data.reshape(num, height * width))\n",
    "                # n_comp = ((np.cumsum(pca.explained_variance_ratio_) > 0.25) != 0).argmax()\n",
    "                # rec = np.matmul(projected[:, :n_comp], pca.components_[:n_comp])\n",
    "                rec = data.reshape(-1, 28,28)\n",
    "                print(rec.shape)\n",
    "                saved_path = os.path.join(working_dir, img_saving_path)\n",
    "                if not os.path.exists(saved_path):\n",
    "                    os.makedirs(saved_path)\n",
    "                saved_name = key + '.npy'\n",
    "                np.save(os.path.join(saved_path, saved_name), rec)\n",
    "            else:\n",
    "                data = np.frombuffer(f.read(), np.uint8)\n",
    "\n",
    "                saved_path = os.path.join(working_dir, labels_saving_path)\n",
    "                if not os.path.exists(saved_path):\n",
    "                    os.makedirs(saved_path)\n",
    "                saved_name = key + '.npy'\n",
    "                np.save(os.path.join(saved_path, saved_name), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script working directory: /home/jjlee/datasets\n",
      "file: train_data\n",
      "size of train_data : 60000\n",
      "(60000, 28, 28)\n",
      "file: train_labels\n",
      "size of train_labels : 60000\n",
      "file: test_data\n",
      "size of test_data : 10000\n",
      "(10000, 28, 28)\n",
      "file: test_labels\n",
      "size of test_labels : 10000\n"
     ]
    }
   ],
   "source": [
    "mnist_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_names(noise_dir):\n",
    "    csv = pd.read_csv(os.path.join(noise_dir, 'meta/esc50.csv'))\n",
    "\n",
    "    # sample one recording from each category\n",
    "    recordings = csv.groupby('target')['filename'].apply(lambda cat: cat.sample(1)).reset_index()['filename']\n",
    "    file_names = recordings.tolist()\n",
    "    file_names = [os.path.join(noise_dir, 'audio', i) for i in file_names]\n",
    "\n",
    "    return file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Raw Audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_wav(audio_dir, file_name, noise_path, noise_power):\n",
    "\n",
    "    audio_path = os.path.join(audio_dir, file_name)\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    y1, sr1 = librosa.load(noise_path, sr=None)\n",
    "    sampling_rate = None\n",
    "\n",
    "    # using the min sample rate\n",
    "    if sr1 > sr:\n",
    "        y1 = librosa.resample(y1, orig_sr=sr1, target_sr=sr)\n",
    "        sampling_rate = sr\n",
    "    else:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=sr1)\n",
    "        sampling_rate = sr1\n",
    "\n",
    "\n",
    "    if len(y) < len(y1):\n",
    "        samples = y + noise_power * y1[:len(y)]\n",
    "    else:\n",
    "        samples = y[:len(y1)] + noise_power * y1\n",
    "\n",
    "    return samples, sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dir='./raw_data/FSDD/'\n",
    "saving_dir='./avmnist/audio'\n",
    "noise_dir='./raw_data/ESC-50/'\n",
    "noise_power=0\n",
    "labels_dir='./avmnist/'\n",
    "\n",
    "\n",
    "wav_dir = audio_dir\n",
    "file_names = [f for f in os.listdir(wav_dir) if os.path.isfile(os.path.join(wav_dir, f)) and '.wav' in f]\n",
    "\n",
    "if len(file_names) == 0:\n",
    "    print('No .wav file in %s' % wav_dir)\n",
    "    exit(1)\n",
    "\n",
    "noise_names = get_noise_names(noise_dir)\n",
    "\n",
    "train_noise_names = noise_names[:40]\n",
    "test_noise_names = noise_names[-10:]\n",
    "\n",
    "train_category = {str(i): list() for i in range(10)}\n",
    "test_category = {str(i): list() for i in range(10)}\n",
    "\n",
    "test_wav_idx = [i for i in range(40, 50)]\n",
    "for file_name in file_names:\n",
    "    idx = file_name.rfind('_') + 1\n",
    "    if int(file_name[idx:-4]) not in test_wav_idx:\n",
    "        train_category[file_name[0]].append(file_name)\n",
    "    else:\n",
    "        test_category[file_name[0]].append(file_name)\n",
    "\n",
    "train_labels = np.load(os.path.join(labels_dir, 'train_labels.npy'))\n",
    "test_labels = np.load(os.path.join(labels_dir, 'test_labels.npy'))\n",
    "train_names = []\n",
    "train_noises = []\n",
    "test_names = []\n",
    "test_noises = []\n",
    "\n",
    "idx_list = [0 for i in range(10)]\n",
    "noise_idx = 0\n",
    "for train_label in train_labels:\n",
    "    train_names.append(train_category[str(train_label)][idx_list[train_label]])\n",
    "    idx_list[train_label] += 1\n",
    "    idx_list[train_label] %= 160\n",
    "\n",
    "    train_noises.append(train_noise_names[noise_idx])\n",
    "    noise_idx += 1\n",
    "    noise_idx %= 40\n",
    "\n",
    "idx_list = [0 for i in range(10)]\n",
    "noise_idx = 0\n",
    "for test_label in test_labels:\n",
    "    test_names.append(test_category[str(test_label)][idx_list[test_label]])\n",
    "    idx_list[test_label] += 1\n",
    "    idx_list[test_label] %= 40\n",
    "\n",
    "    test_noises.append(test_noise_names[noise_idx])\n",
    "    noise_idx += 1\n",
    "    noise_idx %= 10\n",
    "\n",
    "names = train_names + test_names\n",
    "noises = train_noises + test_noises\n",
    "\n",
    "\n",
    "data = []\n",
    "for i in range(len(names)):\n",
    "    samples, sampling_rate = save_wav(audio_dir, names[i], noises[i], noise_power)\n",
    "    data.append(samples)\n",
    "    if i % 1000 == 0:\n",
    "        print(samples.shape)\n",
    "    file_name = os.path.join(saving_dir, f'audio_mnist_{i+1}.wav')\n",
    "    sf.write(file_name, samples, sampling_rate, format='wav')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav_to_spectrogram(audio_dir, file_name, noise_path, f_length, t_length, noise_power):\n",
    "    \"\"\" Creates a spectrogram of a wav file.\n",
    "\n",
    "    :param audio_dir: path of wav files\n",
    "    :param file_name: file name of the wav file to process\n",
    "    :param noise_path: path of noise wav file\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    audio_path = os.path.join(audio_dir, file_name)\n",
    "    y, sr = librosa.load(audio_path, sr=None)\n",
    "    y1, sr1 = librosa.load(noise_path, sr=None)\n",
    "\n",
    "    min_seg_length = int(np.ceil(len(y) / t_length))\n",
    "    time_seg_length = min_seg_length\n",
    "    noverlap = 0\n",
    "    flag = False\n",
    "    for i in range(min_seg_length - 1, len(y)):\n",
    "        for j in range(i):\n",
    "            if 113 * i - 112 * j > len(y) >= 112 * i - 111 * j:\n",
    "                noverlap = j\n",
    "                time_seg_length = i\n",
    "                flag = True\n",
    "                break\n",
    "        if flag:\n",
    "            break\n",
    "\n",
    "    nfft = (f_length - 1) * 2 + 1\n",
    "\n",
    "    if sr1 > sr:\n",
    "        y1 = librosa.resample(y1, orig_sr = sr1, target_sr = sr)\n",
    "\n",
    "    else:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=sr1)\n",
    "\n",
    "    if len(y) < len(y1):\n",
    "        samples = y + noise_power * y1[:len(y)]\n",
    "    else:\n",
    "        samples = y[:len(y1)] + noise_power * y1\n",
    "\n",
    "    fig, ax = plt.subplots(1)\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    ax.axis('off')\n",
    "    pxx, freqs, bins, _ = ax.specgram(x=samples,\n",
    "                                      NFFT=time_seg_length, pad_to=nfft, noverlap=noverlap, Fs=min(sr, sr1),\n",
    "                                      cmap='Greys')\n",
    "    fig.canvas.draw()\n",
    "    width, height = fig.get_size_inches() * fig.get_dpi()\n",
    "    mplimage = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    imarray = np.reshape(mplimage, (int(height), int(width), 3))[:,:,0] # greyscale\n",
    "    plt.close(fig)\n",
    "\n",
    "    return imarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc38ae72bd764dbfb8c9316f58ee2fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating spectrogram:   0%|          | 0/70000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_633295/2399092758.py:48: MatplotlibDeprecationWarning: The tostring_rgb function was deprecated in Matplotlib 3.8 and will be removed in 3.10. Use buffer_rgba instead.\n",
      "  mplimage = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n"
     ]
    }
   ],
   "source": [
    "audio_dir='./raw_data/FSDD/'\n",
    "saving_dir='./avmnist/spectrogram'\n",
    "noise_dir='./raw_data/ESC-50/'\n",
    "noise_power=0\n",
    "labels_dir='./avmnist/'\n",
    "\n",
    "working_dir = './'\n",
    "f_length=112\n",
    "t_length=112\n",
    "\n",
    "wav_dir = audio_dir\n",
    "file_names = [f for f in os.listdir(wav_dir) if os.path.isfile(os.path.join(wav_dir, f)) and '.wav' in f]\n",
    "\n",
    "if len(file_names) == 0:\n",
    "    print('No .wav file in %s' % wav_dir)\n",
    "    exit(1)\n",
    "\n",
    "# set the size of the spectrogarm to (112, 112)\n",
    "plt.rcParams['figure.figsize'] = [1.12, 1.12]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "noise_names = get_noise_names(noise_dir)\n",
    "\n",
    "# 50 noise files\n",
    "train_noise_names = noise_names[:40]\n",
    "test_noise_names = noise_names[-10:]\n",
    "\n",
    "train_category = {str(i): list() for i in range(10)}\n",
    "test_category = {str(i): list() for i in range(10)}\n",
    "\n",
    "test_wav_idx = [i for i in range(40, 50)]\n",
    "for file_name in file_names:\n",
    "    idx = file_name.rfind('_') + 1\n",
    "    if int(file_name[idx:-4]) not in test_wav_idx:\n",
    "        train_category[file_name[0]].append(file_name)\n",
    "    else:\n",
    "        test_category[file_name[0]].append(file_name)\n",
    "\n",
    "train_labels = np.load(os.path.join(labels_dir, 'train_labels.npy'))\n",
    "test_labels = np.load(os.path.join(labels_dir, 'test_labels.npy'))\n",
    "train_names = []\n",
    "train_noises = []\n",
    "test_names = []\n",
    "test_noises = []\n",
    "\n",
    "idx_list = [0 for i in range(10)]\n",
    "noise_idx = 0\n",
    "for train_label in train_labels:\n",
    "    train_names.append(train_category[str(train_label)][idx_list[train_label]])\n",
    "    idx_list[train_label] += 1\n",
    "    idx_list[train_label] %= 160\n",
    "\n",
    "    train_noises.append(train_noise_names[noise_idx])\n",
    "    noise_idx += 1\n",
    "    noise_idx %= 40\n",
    "\n",
    "idx_list = [0 for i in range(10)]\n",
    "noise_idx = 0\n",
    "for test_label in test_labels:\n",
    "    test_names.append(test_category[str(test_label)][idx_list[test_label]])\n",
    "    idx_list[test_label] += 1\n",
    "    idx_list[test_label] %= 40\n",
    "\n",
    "    test_noises.append(test_noise_names[noise_idx])\n",
    "    noise_idx += 1\n",
    "    noise_idx %= 10\n",
    "\n",
    "names = train_names + test_names\n",
    "noises = train_noises + test_noises\n",
    "\n",
    "audio_spectrogram = []\n",
    "for i in tqdm(range(len(names)), desc='Creating spectrogram', total=len(names), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}'):\n",
    "    spectrogram= wav_to_spectrogram(wav_dir, names[i], noises[i], f_length, t_length, noise_power)\n",
    "    audio_spectrogram.append(spectrogram)\n",
    "    spectro_img = Image.fromarray(spectrogram)\n",
    "    spectro_img.save(os.path.join(saving_dir, 'spectrogram_image', f'spectrogram_{i+1}.png'))\n",
    "\n",
    "\n",
    "data = np.array(audio_spectrogram)\n",
    "\n",
    "train_data = data[:60000]\n",
    "test_data = data[60000:]\n",
    "np.save(os.path.join(saving_dir, 'train_data.npy'), train_data)\n",
    "np.save(os.path.join(saving_dir, 'test_data.npy'), test_data)\n",
    "# dir_to_spectrogram(audio_dir, saving_dir, noise_dir, labels_dir, f_length=112, t_length=112, noise_power=noise_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
